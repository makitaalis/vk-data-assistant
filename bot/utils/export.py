"""–§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
import json

import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

import pandas as pd

from bot.config import EXPORT_DATE_FORMAT, EXPORT_COLUMN_WIDTHS
from bot.utils.messages import MESSAGES
from bot.utils.helpers import create_temp_dir
from services.excel_service import ExcelProcessor

logger = logging.getLogger("export")


def restore_processor_from_session(session: Optional[dict]) -> Optional[ExcelProcessor]:
    """
    –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ExcelProcessor –ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–µ—Å—Å–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –∏—Å–ø–æ—Ä—á–µ–Ω.
    """
    if not session:
        return None

    temp_file = session.get("temp_file")
    if not temp_file:
        return None

    file_path = Path(temp_file)
    if not file_path.exists():
        logger.warning("–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª %s –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", file_path)
        return None

    processor = ExcelProcessor()
    links, _, success = processor.load_excel_file(file_path)
    if not success or not links:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª %s –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞", file_path)
        return None

    mapping = session.get("vk_links_mapping")
    if isinstance(mapping, dict):
        normalized = {}
        for link, rows in mapping.items():
            if rows is None:
                continue
            if isinstance(rows, list):
                cleaned = []
                for row in rows:
                    try:
                        cleaned.append(int(row))
                    except (TypeError, ValueError):
                        continue
                if cleaned:
                    normalized[link] = cleaned
            else:
                try:
                    normalized[link] = [int(rows)]
                except (TypeError, ValueError):
                    continue
        if normalized:
            processor.vk_links_mapping = normalized

    return processor


async def create_excel_from_results(
        all_results: Dict[str, Dict[str, Any]],
        links_order: List[str]
) -> List[Tuple[Path, str]]:
    """
    –°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    """
    temp_dir = create_temp_dir(prefix="export")
    ts = datetime.now().strftime(EXPORT_DATE_FORMAT)
    path_result = temp_dir / f"vk_data_{ts}.xlsx"

    files_to_return = []

    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑ —Å–µ—Å—Å–∏–∏ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        from bot.utils.session_manager import get_user_session
        import asyncio

        # –ü–æ–ª—É—á–∞–µ–º ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        # –≠—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ - –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å user_id –≤ —Ñ—É–Ω–∫—Ü–∏—é
        session = None
        processor = None

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if hasattr(asyncio, '_current_task'):
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å processor –≤ —Ñ—É–Ω–∫—Ü–∏—é
            pass

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è DataFrame
        data_for_df = []

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ (–Ω–æ –≤—ã–≤–æ–¥–∏–º –Ω–µ –±–æ–ª–µ–µ –¥–≤—É—Ö)
        max_phones = 0
        for result_data in all_results.values():
            phones = result_data.get("phones", [])
            if isinstance(phones, list):
                max_phones = max(max_phones, len(phones))
        max_phones = min(max_phones, 2) if max_phones else 2

        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Å—ã–ª–∫–∏
        for link in links_order:
            result_data = all_results.get(link, {})

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            phones = result_data.get("phones", [])
            if phones is None:
                phones = []
            elif isinstance(phones, str):
                if phones.startswith('['):
                    try:
                        phones = json.loads(phones)
                    except:
                        phones = []
                else:
                    phones = [phones] if phones else []
            elif not isinstance(phones, list):
                phones = []

            phones = [str(p) for p in phones if p][:2]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –§–ò–û –∏ –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è
            full_name = result_data.get("full_name", "")
            birth_date = result_data.get("birth_date", "")

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å —Å—Å—ã–ª–∫–æ–π –∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
            row_data = {"–°—Å—ã–ª–∫–∞ VK": link}
            row_data["–§–ò–û"] = full_name
            row_data["–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è"] = birth_date

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            for i in range(max_phones):
                col_name = f"–¢–µ–ª–µ—Ñ–æ–Ω{i + 1}"
                row_data[col_name] = phones[i] if i < len(phones) else ""

            data_for_df.append(row_data)

        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(data_for_df)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
        with pd.ExcelWriter(path_result, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã')

            # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
            worksheet = writer.sheets['–†–µ–∑—É–ª—å—Ç–∞—Ç—ã']
            for column in worksheet.columns:
                column_letter = column[0].column_letter
                column_title = str(column[0].value)

                if column_title == "–°—Å—ã–ª–∫–∞ VK":
                    worksheet.column_dimensions[column_letter].width = 50
                elif column_title == "–§–ò–û":
                    worksheet.column_dimensions[column_letter].width = 30
                elif column_title == "–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è":
                    worksheet.column_dimensions[column_letter].width = 15
                elif column_title.startswith("–¢–µ–ª–µ—Ñ–æ–Ω"):
                    worksheet.column_dimensions[column_letter].width = 15

        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏: {path_result}")

        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        found_count = sum(1 for data in all_results.values() if data.get("phones"))
        not_found_count = len(links_order) - found_count

        caption = MESSAGES["file_ready"].format(
            total=len(links_order),
            found=found_count,
            not_found=not_found_count
        )

        files_to_return.append((path_result, caption))

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())

    return files_to_return


async def prepare_result_files(
        processor,
        results: Dict[str, Dict[str, Any]],
        links_order: List[str]
) -> List[Tuple[Path, str]]:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Excel, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω.
    """
    # –°—Ç–∞—Ä–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π Excel –¥–æ—Å—Ç—É–ø–µ–Ω
    try:
        if processor and getattr(processor, "original_df", None) is not None:
            temp_dir = create_temp_dir(prefix="export")
            ts = datetime.now().strftime(EXPORT_DATE_FORMAT)
            output_path = temp_dir / f"vk_data_complete_{ts}.xlsx"

            success = processor.save_results_with_original_data(results, output_path)
            if success:
                found_count = sum(1 for data in results.values() if data.get("phones"))
                not_found_count = len(links_order) - found_count

                caption = (
                    "üìä –§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≥–æ—Ç–æ–≤!\n\n"
                    f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(links_order)} —Å—Å—ã–ª–æ–∫\n"
                    f"üì± –ù–∞–π–¥–µ–Ω—ã —Ç–µ–ª–µ—Ñ–æ–Ω—ã: {found_count}\n"
                    f"‚ùå –ë–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤: {not_found_count}\n\n"
                    "üíæ –í—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!"
                )
                return [(output_path, caption)]
            else:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç.")
    except Exception as exc:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {exc}")

    # –§–æ–ª–±—ç–∫: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –±–µ–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    return await create_excel_from_results(results, links_order)


async def create_json_report(data: Dict[str, Any], filename_prefix: str = "report") -> Path:
    """
    –°–æ–∑–¥–∞–µ—Ç JSON –æ—Ç—á–µ—Ç

    Args:
        data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        filename_prefix: –ü—Ä–µ—Ñ–∏–∫—Å –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞

    Returns:
        Path –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    import json

    temp_dir = create_temp_dir(prefix="export")
    ts = datetime.now().strftime(EXPORT_DATE_FORMAT)
    json_path = temp_dir / f"{filename_prefix}_{ts}.json"

    try:
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω JSON –æ—Ç—á–µ—Ç: {json_path}")
        return json_path

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ JSON –æ—Ç—á–µ—Ç–∞: {e}")
        raise


async def export_statistics_report(stats: Dict[str, Any]) -> Path:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ Excel

    Args:
        stats: –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π

    Returns:
        Path –∫ —Ñ–∞–π–ª—É
    """
    temp_dir = create_temp_dir(prefix="export")
    ts = datetime.now().strftime(EXPORT_DATE_FORMAT)
    path = temp_dir / f"statistics_{ts}.xlsx"

    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ DataFrame –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤
        with pd.ExcelWriter(path, engine='openpyxl') as writer:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            general_stats = pd.DataFrame([{
                "–ú–µ—Ç—Ä–∏–∫–∞": "–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å—Å—ã–ª–æ–∫",
                "–ó–Ω–∞—á–µ–Ω–∏–µ": stats.get("total_checked", 0)
            }, {
                "–ú–µ—Ç—Ä–∏–∫–∞": "–ù–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö",
                "–ó–Ω–∞—á–µ–Ω–∏–µ": stats.get("found_data_count", 0)
            }, {
                "–ú–µ—Ç—Ä–∏–∫–∞": "–ë–µ–∑ –¥–∞–Ω–Ω—ã—Ö",
                "–ó–Ω–∞—á–µ–Ω–∏–µ": stats.get("without_data_count", 0)
            }, {
                "–ú–µ—Ç—Ä–∏–∫–∞": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)",
                "–ó–Ω–∞—á–µ–Ω–∏–µ": stats.get("efficiency", 0)
            }])

            general_stats.to_excel(writer, sheet_name="–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", index=False)

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            worksheet = writer.sheets["–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"]
            worksheet.column_dimensions['A'].width = 30
            worksheet.column_dimensions['B'].width = 15

        logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {path}")
        return path

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise


# –í bot/utils/export.py –¥–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
async def create_excel_with_original_data(
        all_results: Dict[str, Dict[str, Any]],
        links_order: List[str],
        processor: Optional['ExcelProcessor'] = None
) -> List[Tuple[Path, str]]:
    """
    –°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏
    """
    temp_dir = create_temp_dir(prefix="export")
    ts = datetime.now().strftime(EXPORT_DATE_FORMAT)
    files_to_return = []

    try:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º
        if processor and processor.original_df is not None:
            path_result = temp_dir / f"vk_data_complete_{ts}.xlsx"

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            success = processor.save_results_with_original_data(
                all_results,
                path_result
            )

            if success:
                # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                found_count = sum(1 for data in all_results.values() if data.get("phones"))
                not_found_count = len(links_order) - found_count

                caption = f"""üìä –§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≥–æ—Ç–æ–≤!

‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(links_order)} —Å—Å—ã–ª–æ–∫
üì± –ù–∞–π–¥–µ–Ω—ã —Ç–µ–ª–µ—Ñ–æ–Ω—ã: {found_count}
‚ùå –ë–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤: {not_found_count}

üíæ –í—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!"""

                files_to_return.append((path_result, caption))
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
            return await create_excel_from_results(all_results, links_order)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())

    return files_to_return
