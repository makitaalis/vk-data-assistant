"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""

import logging
import tempfile
from pathlib import Path

import pandas as pd
from aiogram import Router, F
from aiogram.types import Message, CallbackQuery

from bot.config import ADMIN_IDS, MAX_LINKS_PER_FILE, ENABLE_DUPLICATE_REMOVAL
from bot.handlers.search import start_processing
from bot.keyboards.inline import (
    duplicate_actions_kb,
    main_menu_kb,
    back_to_menu_kb,
    file_action_menu_kb,
    analysis_results_kb,
    file_duplicates_menu_kb
)
from bot.utils.messages import MESSAGES
from bot.utils.session_manager import (
    get_user_session,
    clear_user_session,
    save_user_session
)
from db_loader import DatabaseLoader
from db_module import VKDatabase
from services.analysis_service import FileAnalyzer
from services.excel_service import ExcelProcessor

router = Router()
logger = logging.getLogger("files_handler")


@router.message(F.document)
async def on_document(msg: Message, db: VKDatabase, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    user_id = msg.from_user.id

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    session = await get_user_session(user_id)

    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –∑–∞–≥—Ä—É–∑–∫–∏ –ë–î
    if session and session.get("db_load_mode"):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        if user_id not in ADMIN_IDS:
            await msg.answer(MESSAGES["error_no_access"])
            return

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î
        await handle_db_load(msg, db)
        return

    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞
    if not msg.document.file_name.endswith(".xlsx"):
        await msg.answer(MESSAGES["error_file_format"], reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    await handle_excel_file(msg, bot)


async def handle_excel_file(msg: Message, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
    user_id = msg.from_user.id

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –∏ —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
    temp_dir = Path(tempfile.mkdtemp())
    path_in = temp_dir / msg.document.file_name
    await bot.download(msg.document.file_id, destination=path_in)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ExcelProcessor –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    processor = ExcelProcessor()
    links, row_indices, success = processor.load_excel_file(path_in)

    if not success or not links:
        await msg.answer(
            MESSAGES["error_no_vk_links"],
            reply_markup=main_menu_kb(user_id, ADMIN_IDS)
        )
        return

    # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    duplicate_analysis = processor.get_duplicate_analysis()
    file_info = processor.get_file_info()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –≤ —Å–µ—Å—Å–∏—é
    session = {
        'temp_file': str(path_in),
        'file_name': msg.document.file_name,
        'file_mode': 'pending',
        'processor': processor,
        'duplicate_analysis': duplicate_analysis,
        'file_info': file_info
    }
    await save_user_session(user_id, session)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –ª–∏–º–∏—Ç
    if duplicate_analysis['total_links'] > MAX_LINKS_PER_FILE:
        await msg.answer(
            MESSAGES["error_file_too_large"].format(
                total=duplicate_analysis['total_links'],
                max_links=MAX_LINKS_PER_FILE
            ),
            reply_markup=main_menu_kb(user_id, ADMIN_IDS)
        )
        return

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ —Å —É—á–µ—Ç–æ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    if ENABLE_DUPLICATE_REMOVAL and duplicate_analysis['duplicate_count'] > 0:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Ñ–∞–π–ª–∞, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        prompt_text = MESSAGES["file_with_duplicates"].format(
            filename=msg.document.file_name,
            total_links=duplicate_analysis['total_links'],
            unique_links=duplicate_analysis['unique_links'],
            duplicate_count=duplicate_analysis['duplicate_count'],
            duplicate_percent=duplicate_analysis['duplicate_percent']
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–ø –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö
        if duplicate_analysis['top_duplicates']:
            top_text = "\n\n<b>üîù –¢–æ–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:</b>\n"
            for i, (link, count) in enumerate(duplicate_analysis['top_duplicates'][:3], 1):
                top_text += f"{i}. <code>{link}</code> - {count} —Ä–∞–∑\n"
            prompt_text += top_text

        await msg.answer(prompt_text, reply_markup=file_duplicates_menu_kb())
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –º–µ–Ω—é –µ—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç
        prompt_text = MESSAGES["file_action_prompt"].format(
            filename=msg.document.file_name,
            size=duplicate_analysis['unique_links']
        )
        await msg.answer(prompt_text, reply_markup=file_action_menu_kb())


async def handle_db_load(msg: Message, db: VKDatabase):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î"""
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
    documents = []
    if msg.document:
        documents.append(msg.document)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    loader = DatabaseLoader(db)
    total_stats = {
        "files_count": 0,
        "added": 0,
        "updated": 0,
        "errors": 0,
        "duplicates": 0
    }

    status_msg = await msg.answer("üîÑ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")

    for doc in documents:
        if not doc.file_name.endswith('.xlsx'):
            continue

        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            temp_dir = Path(tempfile.mkdtemp())
            file_path = temp_dir / doc.file_name
            await msg.bot.download(doc.file_id, destination=file_path)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –ë–î
            stats = await loader.load_from_excel(file_path, msg.from_user.id)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–≤—è–∑–∏
            records, _ = loader.process_excel_file(file_path)
            network_data = loader.find_all_related_data(records)

            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_stats["files_count"] += 1
            total_stats["added"] += stats["added"]
            total_stats["updated"] += stats["updated"]
            total_stats["errors"] += stats["errors"]
            total_stats["duplicates"] += stats.get("duplicates", 0)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            status_text = f"""üîÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_stats['files_count']}
–î–æ–±–∞–≤–ª–µ–Ω–æ: {total_stats['added']}, –û–±–Ω–æ–≤–ª–µ–Ω–æ: {total_stats['updated']}
–î—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {total_stats['duplicates']}

üìä –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π:
–¢–µ–ª–µ—Ñ–æ–Ω–æ–≤ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ VK: {network_data['stats']['phones_with_multiple_vk']}
VK —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {network_data['stats']['vk_with_multiple_phones']}"""

            await status_msg.edit_text(status_text)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {doc.file_name}: {e}")
            total_stats["errors"] += 1

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î
    db_stats = await db.get_database_statistics()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    complete_text = MESSAGES["db_load_complete"].format(
        files_count=total_stats["files_count"],
        added=total_stats["added"],
        updated=total_stats["updated"],
        duplicates=total_stats["duplicates"],
        errors=total_stats["errors"],
        total_records=db_stats["total_records"],
        with_data=db_stats["with_data"],
        without_data=db_stats["without_data"]
    )

    await status_msg.edit_text(complete_text, reply_markup=back_to_menu_kb())

    # –û—á–∏—â–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–≥—Ä—É–∑–∫–∏ –ë–î
    await clear_user_session(msg.from_user.id)


@router.callback_query(F.data == "analyze_only")
async def on_analyze_only(call: CallbackQuery, db: VKDatabase):
    """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    await call.answer("üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑...")
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('temp_file'):
        await call.message.edit_text("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞
    progress_msg = await call.message.edit_text(
        MESSAGES["analysis_in_progress"].format(
            vk_status="üîÑ",
            phone_status="‚è≥",
            network_status="‚è≥",
            duplicate_status="‚è≥"
        )
    )

    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        file_path = Path(session['temp_file'])
        analyzer = FileAnalyzer(db)

        # –ü–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—Ç–∞—Ç—É—Å–∞
        await progress_msg.edit_text(
            MESSAGES["analysis_in_progress"].format(
                vk_status="‚úÖ",
                phone_status="üîÑ",
                network_status="‚è≥",
                duplicate_status="‚è≥"
            )
        )

        analysis = await analyzer.analyze_file(file_path)

        await progress_msg.edit_text(
            MESSAGES["analysis_in_progress"].format(
                vk_status="‚úÖ",
                phone_status="‚úÖ",
                network_status="üîÑ",
                duplicate_status="‚è≥"
            )
        )

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_text = await analyzer.format_analysis_message(analysis)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å–µ—Å—Å–∏—é
        session['analysis_result'] = analysis
        session['file_mode'] = 'analyzed'
        await save_user_session(user_id, session)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await progress_msg.edit_text(result_text, reply_markup=analysis_results_kb())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}")
        await progress_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {str(e)}",
            reply_markup=back_to_menu_kb()
        )


@router.callback_query(F.data == "process_only")
async def on_process_only(call: CallbackQuery, db: VKDatabase, vk_service, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    await call.answer("üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('temp_file'):
        await call.message.edit_text("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    file_path = Path(session['temp_file'])
    processor = session.get('processor')

    if not processor:
        # –ï—Å–ª–∏ processor –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        processor = ExcelProcessor()
        links, row_indices, success = processor.load_excel_file(file_path)

        if not success or not links:
            await call.message.edit_text(
                MESSAGES["error_no_vk_links"],
                reply_markup=main_menu_kb(user_id, ADMIN_IDS)
            )
            return
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π processor
        links = processor.get_links_without_duplicates()

    # –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    from bot.handlers.balance import check_balance_before_processing
    if not await check_balance_before_processing(call.message, len(links), vk_service):
        return

    # –ù–û–í–û–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    from db_loader import DatabaseLoader
    loader = DatabaseLoader(db)
    records, _ = loader.process_excel_file(file_path)

    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π VK —Å—Å—ã–ª–∫–∏
    phones_map = {}
    for record in records:
        if not record["link"].startswith("phone:"):
            phones_map[record["link"]] = record.get("phones", [])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–µ—Å—Å–∏—é —Å processor
    session_data = {
        "links": links,
        "links_order": links,
        "results": {},
        "all_links": links,
        "temp_file": session.get('temp_file'),
        "file_name": session.get('file_name'),
        "processor": processor,  # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º processor
        "file_mode": "processing",
        "phones_map": phones_map  # –ù–û–í–û–ï: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ä—Ç—É —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
    }
    await save_user_session(user_id, session_data)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —É—á–µ—Ç–æ–º —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
    duplicate_check = await db.check_duplicates_extended(links, phones_map)

    # –ï—Å–ª–∏ –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑
    total = len(links)
    stats = duplicate_check["stats"]

    # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    total_duplicates = stats["duplicate_by_vk"] + stats["duplicate_by_phone"] + stats["duplicate_by_both"]

    if total_duplicates > 0:
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
        with_data_count = len(duplicate_check["duplicates_with_data"])
        no_data_count = len(duplicate_check["duplicates_no_data"])

        analysis_text = f"""üìä <b>–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω!</b>

üìÅ –§–∞–π–ª: <code>{session.get('file_name', '—Ñ–∞–π–ª')}</code>

<b>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ VK —Å—Å—ã–ª–æ–∫:</b>
- –í—Å–µ–≥–æ: {total}
- –ù–æ–≤—ã—Ö: {stats['new']}
- –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ VK: {stats['duplicate_by_vk'] + stats['duplicate_by_both']}

<b>üì± –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤:</b>
- –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º: {stats['duplicate_by_phone'] + stats['duplicate_by_both']}

<b>üìã –ò—Ç–æ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_duplicates}</b>
- –° –¥–∞–Ω–Ω—ã–º–∏: {with_data_count}
- –ë–µ–∑ –¥–∞–Ω–Ω—ã—Ö: {no_data_count + len(duplicate_check.get('duplicate_phones', {}))}

<b>–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏?</b>"""

        await call.message.edit_text(analysis_text, reply_markup=duplicate_actions_kb())

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º duplicate_check
        session_data["duplicate_check"] = duplicate_check
        await save_user_session(user_id, session_data)
    else:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        await call.message.edit_text(f"üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(links)} —Å—Å—ã–ª–æ–∫...")
        await start_processing(call.message, links, processor, duplicate_check, user_id, db, vk_service, bot)


@router.callback_query(F.data == "process_with_duplicates")
async def on_process_with_duplicates(call: CallbackQuery, db: VKDatabase, vk_service, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏"""
    await call.answer("üì§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤—Å–µ —Å—Å—ã–ª–∫–∏...")
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('processor'):
        await call.message.edit_text("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    processor = session['processor']
    all_links = processor.all_links_found  # –í—Å–µ —Å—Å—ã–ª–∫–∏ –≤–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
    from bot.handlers.balance import check_balance_before_processing
    if not await check_balance_before_processing(call.message, len(all_links), vk_service):
        return

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    session_data = {
        "links": all_links,
        "links_order": all_links,
        "results": {},
        "all_links": all_links,
        "temp_file": session.get('temp_file'),
        "file_name": session.get('file_name'),
        "processor": processor,
        "file_mode": "processing"
    }
    await save_user_session(user_id, session_data)

    await call.message.edit_text(f"üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(all_links)} —Å—Å—ã–ª–æ–∫ (–≤–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã)...")
    await start_processing(call.message, all_links, processor, {}, user_id, db, vk_service, bot)


@router.callback_query(F.data == "process_unique_only")
async def on_process_unique_only(call: CallbackQuery, db: VKDatabase, vk_service, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
    await call.answer("üîç –£–¥–∞–ª—è—é –¥—É–±–ª–∏–∫–∞—Ç—ã...")
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('processor'):
        await call.message.edit_text("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    processor = session['processor']
    unique_links = processor.get_links_without_duplicates()
    duplicate_analysis = processor.get_duplicate_analysis()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±—ã–ª–æ —É–¥–∞–ª–µ–Ω–æ
    await call.message.edit_text(
        MESSAGES["duplicates_removed"].format(
            removed_count=duplicate_analysis['duplicate_count'],
            unique_count=len(unique_links)
        )
    )

    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø–æ–∫–∞–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    import asyncio
    await asyncio.sleep(1.5)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
    from bot.handlers.balance import check_balance_before_processing
    if not await check_balance_before_processing(call.message, len(unique_links), vk_service):
        return

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    session_data = {
        "links": unique_links,
        "links_order": unique_links,
        "results": {},
        "all_links": unique_links,
        "temp_file": session.get('temp_file'),
        "file_name": session.get('file_name'),
        "processor": processor,
        "file_mode": "processing"
    }
    await save_user_session(user_id, session_data)

    await call.message.edit_text(f"üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(unique_links)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫...")
    await start_processing(call.message, unique_links, processor, {}, user_id, db, vk_service, bot)


@router.callback_query(F.data == "show_duplicate_details")
async def on_show_duplicate_details(call: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    await call.answer()
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('duplicate_analysis'):
        await call.message.edit_text("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    duplicate_analysis = session['duplicate_analysis']

    details_text = MESSAGES["duplicate_details"].format(
        total_duplicates=duplicate_analysis['duplicate_count'],
        unique_duplicates=len(duplicate_analysis['duplicates'])
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–ø –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö
    if duplicate_analysis['top_duplicates']:
        details_text += "\n\n<b>üîù –¢–æ–ø-10 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:</b>\n\n"
        for i, (link, count) in enumerate(duplicate_analysis['top_duplicates'], 1):
            rows = duplicate_analysis['duplicate_rows'].get(link, [])[:5]
            rows_text = ", ".join(map(str, rows))
            if len(duplicate_analysis['duplicate_rows'].get(link, [])) > 5:
                rows_text += "..."

            details_text += f"{i}. <code>{link}</code>\n"
            details_text += f"   üìä –í—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è: {count} —Ä–∞–∑\n"
            details_text += f"   üìã –°—Ç—Ä–æ–∫–∏ Excel: {rows_text}\n\n"

    await call.message.answer(details_text, reply_markup=back_to_menu_kb())


@router.callback_query(F.data == "analyze_and_process")
async def on_analyze_and_process(call: CallbackQuery, db: VKDatabase):
    """–ê–Ω–∞–ª–∏–∑ –∏ –∑–∞—Ç–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
    # –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    await on_analyze_only(call, db)


@router.callback_query(F.data == "process_after_analysis")
async def on_process_after_analysis(call: CallbackQuery, db: VKDatabase, vk_service, bot):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞"""
    await call.answer("üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
    user_id = call.from_user.id
    session = await get_user_session(user_id)

    if not session or not session.get('analysis_result'):
        await call.message.edit_text("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", reply_markup=main_menu_kb(user_id, ADMIN_IDS))
        return

    analysis = session['analysis_result']
    file_path = Path(session['temp_file'])

    # –ò–∑–≤–ª–µ–∫–∞–µ–º VK —Å—Å—ã–ª–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
    vk_links = [r['link'] for r in analysis['records'] if not r['link'].startswith('phone:')]

    if not vk_links:
        await call.message.edit_text(
            MESSAGES["error_no_vk_links"],
            reply_markup=main_menu_kb(user_id, ADMIN_IDS)
        )
        return

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ExcelProcessor
    processor = ExcelProcessor()
    links, row_indices, success = processor.load_excel_file(file_path)

    if not success:
        await call.message.edit_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞",
            reply_markup=main_menu_kb(user_id, ADMIN_IDS)
        )
        return

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é —Å processor
    session["links"] = vk_links
    session["links_order"] = vk_links
    session["results"] = {}
    session["processor"] = processor  # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º processor
    session["all_links"] = vk_links
    session["file_mode"] = "processing"
    await save_user_session(user_id, session)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
    duplicate_check = analysis['duplicates']['vk']

    await call.message.edit_text(f"üì§ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(vk_links)} —Å—Å—ã–ª–æ–∫...")
    await start_processing(call.message, vk_links, processor, duplicate_check, user_id, db, vk_service, bot)


@router.callback_query(F.data == "cancel_file")
async def on_cancel_file(call: CallbackQuery):
    """–û—Ç–º–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–æ–º"""
    await call.answer()
    user_id = call.from_user.id

    # –û—á–∏—â–∞–µ–º —Å–µ—Å—Å–∏—é
    await clear_user_session(user_id)

    await call.message.edit_text(
        MESSAGES["operation_cancelled"],
        reply_markup=main_menu_kb(user_id, ADMIN_IDS)
    )